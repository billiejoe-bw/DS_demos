{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More about Null Hypothesis Significance Testing (NHST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools as it\n",
    "from scipy.stats import binom_test\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to test whether a coin is fair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](part_of_scientific_method.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Hypothesize:** We have a coin, and we hypothesize that it is biased - the probability of getting heads is not equal to $0.5$.\n",
    "- **Experiment:** We decide to toss the coin 8 times and record the results. This produces heads $7$ times and tails $1$ time.\n",
    "- **Test hypothesis:** Our _null hypothesis_ (that we would like to reject) is that the coin is fair, with probability of heads equal to $0.5$. What do we do now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](sig_testing_slide.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's set $\\alpha = 0.05$ (more on this later). **Now we need to compute a $p$-value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** From 8 tosses, our experiment produced 7 heads. Which outcomes, from tossing a coin 8 times, are \"your effect (or larger)\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** All the outcomes with $0$ heads, $1$ head, $7$ heads or $8$ heads.\n",
    "\n",
    "We are doing a _two-tailed_ test because a biased coin is biased whether it over-produces heads or over-produces tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So let's calculate the $p$-value:** the probability of getting 0, 1, 7 or 8 heads from 8 tosses of a _fair_ coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toss 1</th>\n",
       "      <th>Toss 2</th>\n",
       "      <th>Toss 3</th>\n",
       "      <th>Toss 4</th>\n",
       "      <th>Toss 5</th>\n",
       "      <th>Toss 6</th>\n",
       "      <th>Toss 7</th>\n",
       "      <th>Toss 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Toss 1 Toss 2 Toss 3 Toss 4 Toss 5 Toss 6 Toss 7 Toss 8\n",
       "0        H      H      H      H      H      H      H      H\n",
       "1        H      H      H      H      H      H      H      T\n",
       "2        H      H      H      H      H      H      T      H\n",
       "3        H      H      H      H      H      H      T      T\n",
       "4        H      H      H      H      H      T      H      H\n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...\n",
       "251      T      T      T      T      T      H      T      T\n",
       "252      T      T      T      T      T      T      H      H\n",
       "253      T      T      T      T      T      T      H      T\n",
       "254      T      T      T      T      T      T      T      H\n",
       "255      T      T      T      T      T      T      T      T\n",
       "\n",
       "[256 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tosses = 8\n",
    "tosses_df = pd.DataFrame(list(it.product('HT', repeat=num_tosses)), columns=[f'Toss {i+1}' for i in range(num_tosses)])\n",
    "tosses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toss 1</th>\n",
       "      <th>Toss 2</th>\n",
       "      <th>Toss 3</th>\n",
       "      <th>Toss 4</th>\n",
       "      <th>Toss 5</th>\n",
       "      <th>Toss 6</th>\n",
       "      <th>Toss 7</th>\n",
       "      <th>Toss 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Toss 1 Toss 2 Toss 3 Toss 4 Toss 5 Toss 6 Toss 7 Toss 8\n",
       "183      T      H      T      T      H      T      T      T\n",
       "2        H      H      H      H      H      H      T      H\n",
       "243      T      T      T      T      H      H      T      T\n",
       "233      T      T      T      H      T      H      H      T\n",
       "126      H      T      T      T      T      T      T      H"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tosses_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tosses_df['num_heads'] = tosses_df.apply(lambda row: len([x for x in row if x == 'H']), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toss 1</th>\n",
       "      <th>Toss 2</th>\n",
       "      <th>Toss 3</th>\n",
       "      <th>Toss 4</th>\n",
       "      <th>Toss 5</th>\n",
       "      <th>Toss 6</th>\n",
       "      <th>Toss 7</th>\n",
       "      <th>Toss 8</th>\n",
       "      <th>num_heads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Toss 1 Toss 2 Toss 3 Toss 4 Toss 5 Toss 6 Toss 7 Toss 8  num_heads\n",
       "98       H      T      T      H      H      H      T      H          5\n",
       "162      T      H      T      H      H      H      T      H          5\n",
       "246      T      T      T      T      H      T      T      H          2\n",
       "104      H      T      T      H      T      H      H      H          5\n",
       "242      T      T      T      T      H      H      T      H          3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tosses_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How do we get the $p$-value now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0703125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tosses_df['num_heads'].isin([0, 1, 7, 8]).sum() / tosses_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So we cannot reject the null hypothesis.** So we cannot conclue that the coin is biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `binom_test` from `scipy.stats`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we did the process \"on foot\" for illustration, but fortunately in practise we don't need to; the [Binomial Test](https://en.wikipedia.org/wiki/Binomial_test) is built into `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0703125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tosses_df['num_heads'].isin([0, 1, 7, 8]).sum() / tosses_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0703125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_heads = 7\n",
    "num_tails = 1\n",
    "binom_test(x = [num_heads, num_tails])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gratuitous quokka break:\n",
    "\n",
    "![title](quokka_break_3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can use hypothesis tests like classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a big bag of coins, say $10000$, some of them fair and some of them biased.\n",
    "\n",
    "If our hypothesis test works the way we want, we should be able to use it to **separate the biased coins from the fair coins**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_coins = (  #Â Represent each coin by the probability that it produces heads\n",
    "    \n",
    "      [0.5] * 5000  # 5000 fair coins\n",
    "    + [0.6] * 2000  # 2000 coins biased towards heads\n",
    "    + [0.4] * 3000  # 3000 coins biased towards tails\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.6, 0.4, 0.6, 0.6, 0.4, 0.6, 0.5, 0.5, 0.5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomState(11).choice(bag_of_coins, size=10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to test a given coin by experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_coin(coin_head_prob, random_state=RandomState(), num_tosses=30, alpha=0.05):\n",
    "    \n",
    "    # Toss the coin as many times as required; count how many heads:\n",
    "    num_heads = (random_state.random_sample(num_tosses) < coin_head_prob).sum()\n",
    "\n",
    "    num_tails = num_tosses - num_heads    \n",
    "\n",
    "    p_value = binom_test(x = [num_heads, num_tails])\n",
    "\n",
    "    if p_value <= alpha:\n",
    "        return \"Biased\"\n",
    "    else:\n",
    "        return \"Fair\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fair'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_coin(0.5, num_tosses=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Biased'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_coin(0.2, num_tosses=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fair'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_coin(0.4, num_tosses=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's test the whole bag of coins, and see how well we do separating the biased coins from the fair coins, _in aggregate_:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bag_of_coins(bag_of_coins, random_state=RandomState(), num_tosses=150, alpha=0.05):\n",
    "\n",
    "    return pd.DataFrame([\n",
    "        {\n",
    "            'actual': \"Fair\" if coin_head_prob == 0.5 else \"Biased\",\n",
    "            'predicted': test_coin(coin_head_prob, random_state=random_state, num_tosses=num_tosses, alpha=alpha)\n",
    "        }\n",
    "        for coin_head_prob in bag_of_coins\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fair</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fair</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fair</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fair</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Biased</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Biased</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Biased</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Biased</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Biased</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual predicted\n",
       "0       Fair      Fair\n",
       "1       Fair      Fair\n",
       "2       Fair      Fair\n",
       "3       Fair      Fair\n",
       "4       Fair      Fair\n",
       "...      ...       ...\n",
       "9995  Biased      Fair\n",
       "9996  Biased    Biased\n",
       "9997  Biased    Biased\n",
       "9998  Biased    Biased\n",
       "9999  Biased    Biased\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df = test_bag_of_coins(bag_of_coins, random_state=RandomState(17))\n",
    "test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_results(results_df):\n",
    "\n",
    "    CT = pd.crosstab(results_df['predicted'], results_df['actual'])\n",
    "    display(CT)\n",
    "\n",
    "    true_fair_predictions    = CT['Fair'  ]['Fair'  ]\n",
    "    false_fair_predictions   = CT['Biased']['Fair'  ]\n",
    "    true_biased_predictions  = CT['Biased']['Biased']\n",
    "    false_biased_predictions = CT['Fair'  ]['Biased']\n",
    "    \n",
    "    fair_predictions   = true_fair_predictions   + false_fair_predictions\n",
    "    biased_predictions = true_biased_predictions + false_biased_predictions\n",
    "    \n",
    "    actual_fair   = true_fair_predictions   + false_biased_predictions\n",
    "    actual_biased = true_biased_predictions + false_fair_predictions\n",
    "\n",
    "    print(\"When we predict 'Fair', we are correct %.1f%% of the time and incorrect %.1f%% of the time\" % (\n",
    "        100 * true_fair_predictions / fair_predictions,\n",
    "        100 * (1 - true_fair_predictions / fair_predictions)\n",
    "    ))\n",
    "\n",
    "    print(\"When we predict 'Biased', we are correct %.1f%% of the time and incorrect %.1f%% of the time\" % (\n",
    "        100 * true_biased_predictions / biased_predictions,\n",
    "        100 * (1 - true_biased_predictions / biased_predictions)\n",
    "    ))\n",
    "\n",
    "    print(\"When the coin is 'Fair', we are correct %.1f%% of the time and incorrect %.1f%% of the time\" % (\n",
    "        100 * true_fair_predictions / actual_fair,\n",
    "        100 * (1 - true_fair_predictions / actual_fair)\n",
    "    ))\n",
    "\n",
    "    print(\"When the coin is 'Biased', we are correct %.1f%% of the time and incorrect %.1f%% of the time\" % (\n",
    "        100 * true_biased_predictions / actual_biased,\n",
    "        100 * (1 - true_biased_predictions / actual_biased)\n",
    "    ))\n",
    "    \n",
    "    print(\"We predicted correctly for %.1f%% of coins in the bag\" % \n",
    "         (100 * (true_fair_predictions + true_biased_predictions) / results_df.shape[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>Biased</th>\n",
       "      <th>Fair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biased</th>\n",
       "      <td>3317</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fair</th>\n",
       "      <td>1683</td>\n",
       "      <td>4787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual     Biased  Fair\n",
       "predicted              \n",
       "Biased       3317   213\n",
       "Fair         1683  4787"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we predict 'Fair', we are correct 74.0% of the time and incorrect 26.0% of the time\n",
      "When we predict 'Biased', we are correct 94.0% of the time and incorrect 6.0% of the time\n",
      "When the coin is 'Fair', we are correct 95.7% of the time and incorrect 4.3% of the time\n",
      "When the coin is 'Biased', we are correct 66.3% of the time and incorrect 33.7% of the time\n",
      "We predicted correctly for 81.0% of coins in the bag\n"
     ]
    }
   ],
   "source": [
    "summarise_results(test_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That worked pretty well huh?** The diagonal cells of our confusion matrix are bigger than the off-diagonal ones, and we have 81% accuracy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment by changing one or more of the following parameters:\n",
    "\n",
    "- the threshold $\\alpha$\n",
    "- the number of tosses performed in each experiment\n",
    "- the balance of biased vs fair coins in the bag\n",
    "- the level of bias in the biased coins\n",
    "\n",
    "Please play fair and don't scroll down the notebook yet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_bag_of_coins = (\n",
    "      [0.5] * 5000  # 5000 fair coins\n",
    "    + [0.6] * 2000  # 2000 coins biased towards heads\n",
    "    + [0.4] * 3000  # 3000 coins biased towards tails\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>Biased</th>\n",
       "      <th>Fair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biased</th>\n",
       "      <td>3317</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fair</th>\n",
       "      <td>1683</td>\n",
       "      <td>4787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual     Biased  Fair\n",
       "predicted              \n",
       "Biased       3317   213\n",
       "Fair         1683  4787"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we predict 'Fair', we are correct 74.0% of the time and incorrect 26.0% of the time\n",
      "When we predict 'Biased', we are correct 94.0% of the time and incorrect 6.0% of the time\n",
      "When the coin is 'Fair', we are correct 95.7% of the time and incorrect 4.3% of the time\n",
      "When the coin is 'Biased', we are correct 66.3% of the time and incorrect 33.7% of the time\n",
      "We predicted correctly for 81.0% of coins in the bag\n"
     ]
    }
   ],
   "source": [
    "summarise_results(test_bag_of_coins(\n",
    "    your_bag_of_coins,\n",
    "    random_state=RandomState(17),\n",
    "    num_tosses=150,\n",
    "    alpha=0.05\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making the number of coin tosses in the experiments small diminishes our ability to classify the coins:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>Biased</th>\n",
       "      <th>Fair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biased</th>\n",
       "      <td>854</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fair</th>\n",
       "      <td>4146</td>\n",
       "      <td>4778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual     Biased  Fair\n",
       "predicted              \n",
       "Biased        854   222\n",
       "Fair         4146  4778"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we predict 'Fair', we are correct 53.5% of the time and incorrect 46.5% of the time\n",
      "When we predict 'Biased', we are correct 79.4% of the time and incorrect 20.6% of the time\n",
      "When the coin is 'Fair', we are correct 95.6% of the time and incorrect 4.4% of the time\n",
      "When the coin is 'Biased', we are correct 17.1% of the time and incorrect 82.9% of the time\n",
      "We predicted correctly for 56.3% of coins in the bag\n"
     ]
    }
   ],
   "source": [
    "summarise_results(test_bag_of_coins(\n",
    "    bag_of_coins,\n",
    "    random_state=RandomState(17),\n",
    "    num_tosses=30\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversely making the number of coin tosses very large improves our ability to separate the biased coins from the fair coins:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>Biased</th>\n",
       "      <th>Fair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biased</th>\n",
       "      <td>4970</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fair</th>\n",
       "      <td>30</td>\n",
       "      <td>4776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual     Biased  Fair\n",
       "predicted              \n",
       "Biased       4970   224\n",
       "Fair           30  4776"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we predict 'Fair', we are correct 99.4% of the time and incorrect 0.6% of the time\n",
      "When we predict 'Biased', we are correct 95.7% of the time and incorrect 4.3% of the time\n",
      "When the coin is 'Fair', we are correct 95.5% of the time and incorrect 4.5% of the time\n",
      "When the coin is 'Biased', we are correct 99.4% of the time and incorrect 0.6% of the time\n",
      "We predicted correctly for 97.5% of coins in the bag\n"
     ]
    }
   ],
   "source": [
    "summarise_results(test_bag_of_coins(\n",
    "    bag_of_coins,\n",
    "    random_state=RandomState(17),\n",
    "    num_tosses=500\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making the biased coins more extremely biased makes the task easier:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_bias_bag_of_coins = (\n",
    "      [0.5] * 5000\n",
    "    + [0.8] * 2000  # This probability was 0.6 originally\n",
    "    + [0.2] * 3000  # This probability was 0.4 originally\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>Biased</th>\n",
       "      <th>Fair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biased</th>\n",
       "      <td>5000</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fair</th>\n",
       "      <td>0</td>\n",
       "      <td>4787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual     Biased  Fair\n",
       "predicted              \n",
       "Biased       5000   213\n",
       "Fair            0  4787"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we predict 'Fair', we are correct 100.0% of the time and incorrect 0.0% of the time\n",
      "When we predict 'Biased', we are correct 95.9% of the time and incorrect 4.1% of the time\n",
      "When the coin is 'Fair', we are correct 95.7% of the time and incorrect 4.3% of the time\n",
      "When the coin is 'Biased', we are correct 100.0% of the time and incorrect 0.0% of the time\n",
      "We predicted correctly for 97.9% of coins in the bag\n"
     ]
    }
   ],
   "source": [
    "summarise_results(test_bag_of_coins(\n",
    "    extreme_bias_bag_of_coins,\n",
    "    random_state=RandomState(17)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making the biased coins barely biased makes the task hard:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "slight_bias_bag_of_coins = (\n",
    "      [0.5] * 5000\n",
    "    + [0.55] * 2000  # This probability was 0.6 originally\n",
    "    + [0.48] * 3000  # This probability was 0.2 originally\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>Biased</th>\n",
       "      <th>Fair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biased</th>\n",
       "      <td>613</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fair</th>\n",
       "      <td>4387</td>\n",
       "      <td>4787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual     Biased  Fair\n",
       "predicted              \n",
       "Biased        613   213\n",
       "Fair         4387  4787"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we predict 'Fair', we are correct 52.2% of the time and incorrect 47.8% of the time\n",
      "When we predict 'Biased', we are correct 74.2% of the time and incorrect 25.8% of the time\n",
      "When the coin is 'Fair', we are correct 95.7% of the time and incorrect 4.3% of the time\n",
      "When the coin is 'Biased', we are correct 12.3% of the time and incorrect 87.7% of the time\n",
      "We predicted correctly for 54.0% of coins in the bag\n"
     ]
    }
   ],
   "source": [
    "summarise_results(test_bag_of_coins(\n",
    "    slight_bias_bag_of_coins,\n",
    "    random_state=RandomState(17)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are not doing much better than random guessing (or, you could say, coin tossing :D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decreasing $\\alpha$ makes us more hesitant to label a coin as biased:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>Biased</th>\n",
       "      <th>Fair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biased</th>\n",
       "      <td>909</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fair</th>\n",
       "      <td>4091</td>\n",
       "      <td>4994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual     Biased  Fair\n",
       "predicted              \n",
       "Biased        909     6\n",
       "Fair         4091  4994"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we predict 'Fair', we are correct 55.0% of the time and incorrect 45.0% of the time\n",
      "When we predict 'Biased', we are correct 99.3% of the time and incorrect 0.7% of the time\n",
      "When the coin is 'Fair', we are correct 99.9% of the time and incorrect 0.1% of the time\n",
      "When the coin is 'Biased', we are correct 18.2% of the time and incorrect 81.8% of the time\n",
      "We predicted correctly for 59.0% of coins in the bag\n"
     ]
    }
   ],
   "source": [
    "summarise_results(test_bag_of_coins(\n",
    "    bag_of_coins,\n",
    "    random_state=RandomState(17),\n",
    "    alpha=0.001\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have high precision for identifying biased coins, but we pay for it in terms of low recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Increasing $\\alpha$ makes us more keen to label a coin as biased:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>Biased</th>\n",
       "      <th>Fair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biased</th>\n",
       "      <td>4703</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fair</th>\n",
       "      <td>297</td>\n",
       "      <td>3106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual     Biased  Fair\n",
       "predicted              \n",
       "Biased       4703  1894\n",
       "Fair          297  3106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we predict 'Fair', we are correct 91.3% of the time and incorrect 8.7% of the time\n",
      "When we predict 'Biased', we are correct 71.3% of the time and incorrect 28.7% of the time\n",
      "When the coin is 'Fair', we are correct 62.1% of the time and incorrect 37.9% of the time\n",
      "When the coin is 'Biased', we are correct 94.1% of the time and incorrect 5.9% of the time\n",
      "We predicted correctly for 78.1% of coins in the bag\n"
     ]
    }
   ],
   "source": [
    "summarise_results(test_bag_of_coins(\n",
    "    bag_of_coins,\n",
    "    random_state=RandomState(17),\n",
    "    alpha=0.4\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have high recall for identifying biased coins, but we pay for it in terms of lower precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What happens if biased coins are very common in the bag?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_coins_2 = (\n",
    "      [0.5] * 1000   # 1000 fair coins\n",
    "    + [0.6] * 4500   # 4500 coins biased towards heads\n",
    "    + [0.4] * 4500   # 4500 coins biased towards tails\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>Biased</th>\n",
       "      <th>Fair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biased</th>\n",
       "      <td>5839</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fair</th>\n",
       "      <td>3161</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual     Biased  Fair\n",
       "predicted              \n",
       "Biased       5839    41\n",
       "Fair         3161   959"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we predict 'Fair', we are correct 23.3% of the time and incorrect 76.7% of the time\n",
      "When we predict 'Biased', we are correct 99.3% of the time and incorrect 0.7% of the time\n",
      "When the coin is 'Fair', we are correct 95.9% of the time and incorrect 4.1% of the time\n",
      "When the coin is 'Biased', we are correct 64.9% of the time and incorrect 35.1% of the time\n",
      "We predicted correctly for 68.0% of coins in the bag\n"
     ]
    }
   ],
   "source": [
    "summarise_results(test_bag_of_coins(\n",
    "    bag_of_coins_2,\n",
    "    random_state=RandomState(17)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we seem to _over-predict_ the fair class; now **most of our predictions of fair are wrong**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What happens if biased coins are very rare in the bag?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_coins_3 = (\n",
    "      [0.5] * 9500  # 9500 fair coins\n",
    "    + [0.6] * 250   # 250 coins biased towards heads\n",
    "    + [0.4] * 250   # 250 coins biased towards tails\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>Biased</th>\n",
       "      <th>Fair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biased</th>\n",
       "      <td>323</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fair</th>\n",
       "      <td>177</td>\n",
       "      <td>9101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual     Biased  Fair\n",
       "predicted              \n",
       "Biased        323   399\n",
       "Fair          177  9101"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we predict 'Fair', we are correct 98.1% of the time and incorrect 1.9% of the time\n",
      "When we predict 'Biased', we are correct 44.7% of the time and incorrect 55.3% of the time\n",
      "When the coin is 'Fair', we are correct 95.8% of the time and incorrect 4.2% of the time\n",
      "When the coin is 'Biased', we are correct 64.6% of the time and incorrect 35.4% of the time\n",
      "We predicted correctly for 94.2% of coins in the bag\n"
     ]
    }
   ],
   "source": [
    "summarise_results(test_bag_of_coins(\n",
    "    bag_of_coins_3,\n",
    "    random_state=RandomState(17)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's really interesting here is that **most of the time when we predicted biased, we were wrong**.\n",
    "\n",
    "**Setting $\\alpha$ to a low value value like $0.05$ could not save us from this situation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does that agree with your intuition? Or are you thinking something like\n",
    "\n",
    ">\"Hang on, setting $\\alpha$ to $0.05$ means I should only be able to get it wrong one time in 20\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Food for thought:** This situation - with the thing we are looking for (biased coins) being rare - is **probably closer to what we have in science**. For example, for a given disease, the vast majority of chemical compounds are not an effective treatment.\n",
    "\n",
    "[This fascinating paper](https://royalsocietypublishing.org/doi/10.1098/rsos.140216) argues that this is partly why \"an alarming number of published results cannot be reproduced by other people\", and does a series of simulations like I have done above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the various success and failure rates reported by `summarise_results`, which one(s) if any is/are fixed only by your setting of the threshold $\\alpha$?\n",
    "\n",
    "What do you think about that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gratuitous quokka break:\n",
    "\n",
    "![title](quokka_break_1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hint: look at Bayes' rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above results are puzzling, one way to get intuition is to look at Bayes' rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\text{Fair} \\;|\\; \\text{Observed}) = \\frac{P(\\text{Observed} \\;|\\; \\text{Fair}) \\cdot P(\\text{Fair})}{P(\\text{Observed})}$$\n",
    "\n",
    "or equally\n",
    "\n",
    "$$P(\\text{Fair} \\;|\\; \\text{Observed}) = \\frac{P(\\text{Observed} \\;|\\; \\text{Fair}) \\cdot P(\\text{Fair})}\n",
    "{(P(\\text{Fair})\\cdot P(\\text{Observed} \\;|\\; \\text{Fair}))\n",
    "\\;+\\;\n",
    "(P(\\text{Biased})\\cdot P(\\text{Observed} \\;|\\; \\text{Biased}))\n",
    "}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The $p$-value reported by the significance test is only related to _one part_ of the RHS here, namely $P(\\text{Observed} \\;|\\; \\text{Fair})$; it doesn't reflect any of the other values that go into the RHS.\n",
    "\n",
    "(Related, not equal, by the way, because the $p$-value is not the exact probability of the observed sequence of heads and tails, but instead the probability of any outcome equally or more extreme.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concluding remark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our work at Brandwatch, we won't be testing bags of coins, but we might be testing bags of:\n",
    "\n",
    "- **keywords**: e.g. we want to know which keywords are or are not correlated with sentiment\n",
    "- **times series**: e.g. we have the daily volume time series for a large number of queries, and we want to know which \"really\" show an increasing trend\n",
    "- **pairs of survey variables**: e.g. we want to know which pairs of survey variables show a relationship that we can report as an \"insight\"\n",
    "\n",
    "If we do mass significance testing of things like this, we will need to think carefully about what the results really tell us.\n",
    "\n",
    "For example, simply stating \"we're doing significance testing\" doesn't free us from having to think about the two different kinds of errors we can make, how common these _actually_ are, and how they typically have different costs associated with them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gratuitous quokka appendix:\n",
    "\n",
    "![title](quokka_break_2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS: $p$-values aren't measures of effect size!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first coin here looks to have a much stronger bias, but the $p$-values come out bigger... (because the sample size is different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of heads to tails: 2.00\n",
      "p-value: 0.0021\n"
     ]
    }
   ],
   "source": [
    "num_heads = 60\n",
    "num_tails = 30\n",
    "print(\"Ratio of heads to tails: %.2f\" % (num_heads/num_tails))\n",
    "print(\"p-value: %.4f\" % binom_test(x = [num_heads, num_tails]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of heads to tails: 1.08\n",
      "p-value: 0.0007\n"
     ]
    }
   ],
   "source": [
    "num_heads = 4000\n",
    "num_tails = 3700\n",
    "print(\"Ratio of heads to tails: %.2f\" % (num_heads/num_tails))\n",
    "print(\"p-value: %.4f\" % binom_test(x = [num_heads, num_tails]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Message:** Don't try to compare effect sizes by comparing $p$-values when the sample sizes might be different.\n",
    "\n",
    "**Example:** Suppose instead of coins we have keywords, and instead of heads and tails we have positive and negative mentions. Suppose we are trying to pick out which keyword has the most skewed sentiment. Sure, it might be a good idea to significance-test that there is a skew (not 50/50 positive and negative sentiment) so that we don't show the user keywords where any observed sentiment skew away from 50/50 is plausibly just due to chance.\n",
    "\n",
    "But because different keywords can have radically different sample sizes in our data, it would be wrong to then go on to compare the $p$-values to see which keyword had the greater skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
